# Materials for transfer learning [中文版](https://github.com/dududuAA/Transfer-learning-materials/blob/master/readme.md), [English version](https://github.com/dududuAA/Transfer-learning-materials/blob/master/Readme_English.md) 

update:
* (2020,8,29) 新增龙老师ccdm 2020报告视频
* (2020,9,6) 新增DA paper, 科研方法论相关视频

- [Materials for transfer learning](#materials-for-transfer-learning)
  * [入门参考](#入门参考)
  * [数据集](#数据集)
  * [迁移学习竞赛](#迁移学习竞赛)
  * [CCF截稿日期](#CCF截稿日期)
  * [Excellent Scholars](#excellent-scholars)
  * [新论文追踪](#新论文追踪)
  * [科研方法论](#科研方法论)
  * [好文整理](#好文整理)
  * [会议视频](#会议视频)
  * [Presentation](#presentation)
  * [Other githubs](#other-githubs)
  * [novel papers](#novel_papers)
  * [tutorial collection](#tutorial_collection)
  
## 入门参考
本部分内容适合初学者，将一些本领域中的经典论文按照时间线进行分类、梳理，分为浅层域适应、深度域适应、对抗域适应和域适应领域四部分。

针对每一部分，列举了3-4篇经典论文，建议详读这些经典论文，泛读这些经典论文的后续论文，并对其中的部分算法进行实现。

预期学习时间为2-3个月, 详细计划安排见[入门参考](https://github.com/dududuAA/Transfer-learning-materials/blob/master/discuss/plan.pptx)

围绕这些论文，曾有一个相应的讨论班，相关的日程和资料如下：

   - [week 1](https://github.com/dududuAA/TL_group/tree/master/discuss/week1_10-14)
   - [week 2](https://github.com/dududuAA/TL_group/tree/master/discuss/week2_10-23)
   - [week1 & week2 reference](https://github.com/dududuAA/TL_group/blob/master/discuss/week1%262%E5%8F%82%E8%80%83.pdf)
   - [week 3](https://github.com/dududuAA/TL/tree/master/discuss/week3_10-30)
   - [week 4](https://github.com/dududuAA/TL/tree/master/discuss/week4_11-07)
   - [week 5](https://github.com/dududuAA/TL/tree/master/discuss/week5_11-13)

## 数据集

适用深度网络的数据集

* mnist, svhn, digit, mnistm, cifar, stl (以上皆为.mat格式) [链接](https://box.nju.edu.cn/d/b88420b4d9fd42e78ef5/)
* [Office](https://drive.google.com/file/d/0B4IapRTv9pJ1WGZVd1VDMmhwdlE/view), [Office-Home](https://drive.google.com/file/d/0B81rNlvomiwed0V1YUxQdC1uOTg/view), [VisDA-C](https://github.com/VisionLearningGroup/taskcv-2017-public/tree/master/classification), [Office-Caltech](http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz) from the official websites.

适用非深度网络的数据集(传统方法)

## 迁移学习竞赛
- [VisDA 2017 in ICCV 2017](http://ai.bu.edu/visda-2017/)
- [VisDA 2018 in ECCV 2018](https://ai.bu.edu/visda-2018/)
- [VisDA 2019 in ICCV 2019](https://ai.bu.edu/visda-2019/)
- [VisDA 2020 in ECCV 2020](http://ai.bu.edu/visda-2020/)

## CCF截稿日期
CCF推荐会议每年的举办时间会有稍稍的不同，此列表收集了当年的CCF推荐列表的截稿时间，包括了全部的CCF会议deadline和CCF期刊的special issue, 可作为一个近似参考，详细时间及内容建议查询官网确认。
链接：[Call4Papars](http://www.call4papers.cn:8080/ccf/ccf-8.jsp)

## Excellent Scholars
- [龙明盛 清华大学](http://ise.thss.tsinghua.edu.cn/~mlong/)
- [庄福振 中科院计算所](http://www.intsci.ac.cn/users/zhuangfuzhen/)
- [张宇 南方科技大学](https://yuzhanghk.github.io/)
- [李汶 ETH](http://www.vision.ee.ethz.ch/~liwenw/)
- [王晋东 微软亚洲研究院](http://jd92.wang/)
- [张磊 重庆大学](http://www.leizhang.tk/)
- [Judy Hoffman Georgia Tech](https://www.cc.gatech.edu/~judy/)
- [Kate Aaenko Boston University](https://www.bu.edu/cs/profiles/kate-saenko/)
- [Sinno Jialin Pan NTU](https://www.ntu.edu.sg/home/sinnopan/index.html)
- [Kuniaki Saito Boston University(Ph.D)](http://cs-people.bu.edu/keisaito/)
- [Zhao Han CMU](https://www.cs.cmu.edu/~hzhao1/)
- [宫博庆 Google Research](http://boqinggong.info/)

## 新论文追踪

- [Topic: domain adaptation](http://arxitics.com/search?q=domain%20adaptation&sort=updated)
- [Topic: transfer learning](http://arxitics.com/search?q=transfer%20learning&sort=updated#1904.01376/abstract)
- [Topic: Semi-supervised](http://arxitics.com/search?q=semi-supervised&sort=updated)

## 科研方法论
- 督工 认知模型 [链接](https://www.bilibili.com/video/BV1P7411Y7bG)
- 沈向洋 you are what you read [链接](https://www.bilibili.com/s/video/BV1df4y1m74k)
- 沈向洋 how to read papers 7.18[(私有)](https://box.nju.edu.cn/f/5f40ba30e6a8476eacda/), [文字版](https://mp.weixin.qq.com/s/2iwK369LT3qgSypeSWWdCg)
- 王井东 how to read papers 7.21[(私有, 密码同上)](https://box.nju.edu.cn/f/d37de48554044bbb9f8a/)
- 袁路   how to read papers 7.24[(私有，密码同上)](https://box.nju.edu.cn/f/ae8c7d900b384a88b008/)
- 陈栋   how to read papers 7.27[(私有，密码同上)](https://box.nju.edu.cn/f/6ab5d03878c141de8aeb/)
- 杨蛟龙 how to read papers 7.30[(私有，密码同上)](https://box.nju.edu.cn/f/fd124ffa1b304fdfaa52/)
- 胡瀚   how to read papers 8.2[(私有，密码同上)](https://box.nju.edu.cn/f/c3a79daf9b6e47539f24/)
- 陈东东 how to read papers 8.5[(私有，密码同上)](https://box.nju.edu.cn/f/5cb5912b8736494486d0/)
- 秦涛   do high-quality research [(私有，密码同上)](https://box.nju.edu.cn/f/b77b568e329345cda36b/)
## 好文整理
- 杨强， 从 0 到 1，迁移学习如何登上今日高峰？[链接](https://mp.weixin.qq.com/s/eGHi88TmG-9cYSMz592_yw)
   	
## 会议视频
- [VALSE 2020 7.31-8.5](http://valser.org/2020/#/)
- [ICLR 2020 视频回放(maybe 科学上网)](https://iclr.cc/virtual_2020/calendar.html#tab-Monday)

	
## Presentation
   - [龙明盛 CCDM 2020] [视频](https://www.bilibili.com/video/BV1ZK4y1Y77u?from=search&seid=13208916633723128421) , [ppt](http://ise.thss.tsinghua.edu.cn/~mlong/doc/transfer-learning-theories-and-algorithms-ccdm20.pdf)
   - VALSE Webinar 20-19期 迁移学习 (个人非常推荐, 对新手不友好，对进阶有帮助，质量很高!) [视频](https://www.bilibili.com/video/BV19v411q7jk), [报告简介](https://mp.weixin.qq.com/s/HaLUIlDEP4ThdfSgM5-Gog)
   - [龙明盛_NJU2019 Transfer Learning Theories and Algorithms](https://github.com/dududuAA/TL_group/tree/master/presentation/%E9%BE%99%E6%98%8E%E7%9B%9B_NJU2019_Transfer%20Learning%20Theories%20and%20Algorithms)
   - [龙明盛 Valse 2019 Transfer Learning_From Algorithms to Theories and Back](https://github.com/dududuAA/TL_group/tree/master/presentation/%E9%BE%99%E6%98%8E%E7%9B%9B_valse2019_Transfer%20Learning_From%20Algorithms%20to%20Theories%20and%20Back)
   - [游凯超 智源论坛 2019 领域适配前沿研究--场景、方法与模型选择](https://www.bilibili.com/video/BV15J411W7KX?from=search&seid=8739501206493640960)
   - [王玫   2019 deep_domain_adaptation](https://github.com/dududuAA/TL_group/tree/master/presentation/%E7%8E%8B%E7%8E%AB_2019_deep_domain_adaptation)
   - [吴恩达 NIPS 2016  Nuts and bolts of building AI applications using Deep Learning](https://github.com/dududuAA/TL_group/tree/master/presentation/%E5%90%B4%E6%81%A9%E8%BE%BE_NIPS2016_Nuts%20and%20bolts%20of%20building%20AI%20applications%20using%20Deep%20Learning)
   

## Other githubs
- [王晋东](https://github.com/jindongwang)
- [ThuML](https://github.com/thuml)
- [Awesome-1](https://github.com/zhaoxin94/awsome-domain-adaptation#distance-based-methods)
- [Awesome-2](https://github.com/barebell/DA)

## novel_papers
### 1) novel_papers on transfer learning
|  Title   | Conference/journel + year| Code | Keywords |  Benenit for us |
|  ----  | ----  | ---- | ---- | ---- |
|When Semi-Supervised Learning Meets Transfer Learning: Training Strategies, Models and Datasets(https://arxiv.org/pdf/1812.05313.pdf)|||SSL, TL, experiments|many results related to multiple SSL methods can be seen in this paper|
<--
maybe it is related to semi+source free 
-->
|Unsupervised Transfer Learning for Spatiotemporal Predictive Networks ([paper](http://ise.thss.tsinghua.edu.cn/~mlong/doc/transferable-memory-icml20.pdf))|ICML 2020||||
|Estimating Generalization under Distribution Shifts via Domain-Invariant Representations ([paper](http://people.csail.mit.edu/stefje/papers/chuang_icml20.pdf))|ICML 2020|[code](https://github.com/chingyaoc/estimating-generalization)|new theory|**recommend to read**|
|Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation ([paper](https://arxiv.org/pdf/2006.04996.pdf))|ICML 2020|[code](https://github.com/xiangdal/implicit_alignment)|ideas from theory|**recommend to read**|
|LEEP: A New Measure to Evaluate Transferability of Learned Representations ([paper](https://arxiv.org/pdf/2002.12462.pdf))|ICML 2020||new metric for transferability|easy to use for other tasks|
|Label-Noise Robust Domain Adaptation|ICML2020|||the author is a rising star|
|Progressive Graph Learning for Open-Set Domain Adaptation ([paper](https://arxiv.org/abs/2006.12087))|ICML 2020|[code](https://github.com/BUserName/PGL)|open set DA||
|Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation ([paper](https://arxiv.org/abs/2002.08546))|ICML 2020|[code](https://github.com/tim-learn/SHOT)|source-free DA |**recommend to read, new trneds**|
|Graph Optimal Transport for Cross-Domain Alignment ([paper](https://arxiv.org/pdf/2006.14744v2.pdf))|ICML 2020||graph for DA| connenction with GCN |
|Learning Deep Kernels for Non-Parametric Two-Sample Tests ([paper](https://arxiv.org/pdf/2002.09116.pdf))|ICML 2020|[code](https://github.com/fengliu90/DK-for-TST)|extend MMD to deep||
| Adversarial-Learned Loss for Domain Adaptation  | AAAI 2020 |  | noisy label, adversarial learning ||
|Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection| AAAI 2020 || transfer learning, anamaly detection||
|Dynamic Instance Normalization for Arbitrary Style Transfer|AAAI 2020| |dynamic instance normalization||
|AdaFilter: Adaptive Filter Fine-Tuning for Deep Transfer Learning|AAAI 2020||gated output, fine-tune||
|Bi-Directional Generation for Unsupervised Domain Adaptation|AAAI 2020||differert feature extractor, different classifiers|connection with ICML 2019, the third term|
|Discriminative Adversarial Domain Adaptation|AAAI 2020| | discriminative information with adversarial learning||
|Domain Generalization Using a Mixture of Multiple Latent Domains|AAAI 2020||||
|Multi-Source Distilling Domain Adaptation|AAAI 2020||multi-source||
|Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-Supervision|CVPR 2020|[code](https://github.com/feipan664/IntraDA)|Entropy adversarial based||
|Rethinking Class-Balanced Methods for Long-Tailed Visual Recognition from a Domain Adaptation Perspective|CVPR 2020||long-tailed||
|Unsupervised Domain Adaptation via Structurally Regularized Deep Clustering|CVPR 2020|[code](https://github.com/huitangtang/SRDC-CVPR2020)|cluster||
|Stochastic Classifiers for Unsupervised Domain Adaptation|CVPR 2020||stochastic two classifiers|simialer to MCD|
|Progressive Adversarial Networks for Fine-Grained Domain Adaptation|CVPR 2020||fine-grained|similar to mutil-aspect opinion analysis|
|Model Adaptation: Unsupervised Domain Adaptation without Source Data|CVPR 2020|||**Recommend to read, new problems**|
|Towards Inheritable Models for Open-Set Domain Adaptation|CVPR 2020|[code](https://sites.google.com/view/inheritune)|||
|Joint Disentangling and Adaptation for Cross-Domain Person Re-Identification|ECCV 2020||||
|Extending and Analyzing Self-Supervised Learning Across Domains ([paper](https://arxiv.org/pdf/2004.11992.pdf))|ECCV 2020||||
|Dual Mixup Regularized Learning for Adversarial Domain Adaptation ([paper](https://arxiv.org/pdf/2007.03141.pdf))|ECCV 2020||||
|Label Propagation with Augmented Anchors: A Simple Semi-Supervised Learning baseline for Unsupervised Domain Adaptation ([paper](https://arxiv.org/pdf/2007.07695.pdf)|ECCV 2020|[code](https://github.com/YBZh/Label-Propagation-with-Augmented-Anchors)|SSL reguralization, Anchors|new methods, good writings|
|Do Adversarially Robust ImageNet Models Transfer Better?|arvix 2020|[code](https://github.com/Microsoft/robust-models-transfer)|Many experiments||
|Visualizing Transfer Learning|arvix 2020||interesting||
|A SURVEY ON DOMAIN ADAPTATION THEORY:LEARNING BOUNDS AND THEORETICAL GUARANTEES ([paper](https://arxiv.org/pdf/2004.11829.pdf))|arvix 2020||theory||
|SpotTune: Transfer Learning through Adaptive Fine-tuning ([paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_SpotTune_Transfer_Learning_Through_Adaptive_Fine-Tuning_CVPR_2019_paper.pdf))|CVPR 2019|[code](https://github.com/gyhui14/spottune)||dynamic routing is a general method|
|Parameter Transfer Unit for Deep Neural Networks ([paper](https://arxiv.org/abs/1804.08613))|PAKDD 2019 best paper|||good idea, **recommened  to read**|
|Heterogeneous Domain Adaptation via Soft Transfer Network ([paper](https://arxiv.org/pdf/1908.10552v1.pdf))|ACM MM 2019||||
|Information-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation ([paper](https://icml.cc/2012/papers/566.pdf))|ICML 2012||||
|Joint Disentangling and Adaptation for Cross-Domain Person Re-Identification ([paper](https://arxiv.org/pdf/2007.10315.pdf))|arvix 2020|||Good ideas|
|Towards Recognizing Unseen Categories in Unseen Domains ([paper](https://arxiv.org/pdf/2007.12256.pdf))|arvix 2020|||new problems|
|MiCo: Mixup Co-Training for Semi-Supervised Domain Adaptation ([paper](https://arxiv.org/pdf/2007.12684.pdf))|arvix 2020|||good framework|
|Dynamic Knowledge Distillation for Black-box Hypothesis Transfer Learning ([paper](https://arxiv.org/pdf/2007.12355.pdf)|arvix 2020||||
|Simultaneous Semantic Alignment Network for Heterogeneous Domain Adaptation ([paper](https://arxiv.org/pdf/2008.01677.pdf))|ACM MM 2020|[code](https://github.com/BIT-DA/SSAN)|||
|Learning from a Complementary-label Source Domain: Theory and Algorithms([paper](https://arxiv.org/pdf/2008.01454.pdf))|arvix 2020|[code](https://github.com/Yiyang98/BFUDA)||novel idea|
|Class-Incremental Domain Adaptation([paper](https://arxiv.org/pdf/2008.01389.pdf))|ECCV 2020|||new problems|
|Class-incremental Learning via Deep Model Consolidation ([paper](https://openaccess.thecvf.com/content_WACV_2020/papers/Zhang_Class-incremental_Learning_via_Deep_Model_Consolidation_WACV_2020_paper.pdf))|WACV 2020||||
|Adversarial Graph Representation Adaptation for Cross-Domain Facial Expression Recognition ([paper](https://arxiv.org/pdf/2008.00859.pdf))|ACM MM 2020|||similar idea with us|
|A Review of Single-Source Deep Unsupervised Visual Domain Adaptation [paper](https://arxiv.org/pdf/2009.00155.pdf)|arvix 2020||Review|a good review! It contains many results of the state-of-the-art method|
### 2) novel_papers on related fileds
|  Title   | Conference/journel + year| Code | Keywords |  Benenit for us |
|  ----  | ----  | ---- | ---- | ---- |
| Collaborative Graph Convolutional Networks: Unsupervised Learning Meets Semi-Supervised Learning  | AAAI 2020 |  | unsupervised learning, semi-supervised learning ||
|Self-supervised Label Augmentation via Input Transformations|ICML 2020|[code](https://github.com/hankook/SLA)|self-supervised|ideas can be used to many tasks|
|Learning with Multiple Complementary Labels ([paper](https://arxiv.org/pdf/1912.12927.pdf))|ICML 2020||||
|Deep Divergence Learning ([paper](https://arxiv.org/pdf/2005.02612.pdf))|ICML 2020||divergence||
|Confidence-Aware Learning for Deep Neural Networks ([paper](https://arxiv.org/pdf/2007.01458.pdf))|ICML 2020|[code](https://github.com/daintlab/confidence-aware-learning)|confidence||
|Continual Learning in Human Activity Recognition:an Empirical Analysis of Regularization ([paper](https://arxiv.org/pdf/2007.03032.pdf))|ICML workshop|[code](https://github.com/srvCodes/continual-learning-benchmark)|Continual learning bechmark||
|Automated Phrase Mining from Massive Text Corpora ([paper](https://arxiv.org/pdf/1702.04457.pdf))|||||
|Adversarially-Trained Deep Nets Transfer Better([paper](https://arxiv.org/pdf/2007.05869.pdf)|arvix 2020|||new findings|
|Learning to Combine: Knowledge Aggregation for Multi-Source Domain Adaptation|arvix ([paper](https://arxiv.org/pdf/2007.08801.pdf))|||same ideas with us|

## tutorial_collection
|  Title   | Conference + year| speaker |  Benenit for us |
|  ----  | ----  | ---- | ---- |
|Weakly Supervised Domain Adaptation with Deep Learning ([link](http://mhug.disi.unitn.it/tutorial-acmmm16/pdf/dda-xgw.pdf))| ACM MM 2016 | Xiaogang Wang||
